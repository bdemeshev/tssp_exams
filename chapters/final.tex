% !TEX root = ../tssp_exams.tex
% all problems are copied to stochastic_pro 2024-11-03


% it's good to follow the strategy:
% after exams copy exam here and classify int stochastic_pro

\newpage
\thispagestyle{empty}
\section{Final exam}

\subsection[2023-2024]{\hyperref[sec:sol_kr_04_2023_2024]{2023-2024}}
\label{sec:kr_04_2023_2024} % \label{ссылка сюда}

Short rules: 120 minutes, you may use one A4 cheat-sheet, offline

Date: 2024-04-27

\begin{enumerate}
    \item The variables $X_1$, \ldots, $X_n$ are independent identically distributed with density 
    \[
    f(x) = \begin{cases}
      \lambda \exp(-\lambda (x - \theta)), \text{ if } x\geq \theta \\
      0, \text{ otherwise}.
    \end{cases}  
    \]
    \begin{enumerate}
      \item {[5]} Find the method of moments estimator of $\lambda$ for known value $\theta = 1$ using the first moment. 
      \item {[5]} Find the method of moments estimator of $\lambda$ for unknown value $\theta$ using the first two moments. 
    \end{enumerate}

    \item {[10]} The variables $X_1$, \ldots, $X_n$ are independent and normally distributed $\cN(a, 2a)$.
  
    Find the maximum likelihood estimator of $a$.
  
    Hint: $f(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp(-(x-\mu)^2/2\sigma^2)$.

    \item The variables $X_1$, \ldots, $X_n$ are independent and uniformly distributed $\dUnif[0;a]$ with $a>1$.
    We do not observe $X_i$ directly but we know whether each $X_i$ is larger than 1. 
    Hence we observe the indicators $Y_i = I(X_i > 1)$.
  
    Consider the estimator $\hat a = 1 / (1 - \bar Y)$.
  
    \begin{enumerate}
      \item {[5]} Is $\hat a$ consistent?
      \item {[5]} Is $\hat a$ unbiased for $n=2$?
    \end{enumerate}

    \item The variables $X_1$, \ldots, $X_n$ are independent and have Poisson distribution with intensity rate $\lambda$.
    In other words the probability mass function is given by $\P(X_i = k) = \exp(-\lambda) \lambda^k / k!$.
    
    \begin{enumerate}
      \item {[5]} Find theoretical Fisher information for $\lambda$ contained in the sample. 
      \item {[2]} Derive the maximum likelihood estimator for $\lambda$.
      \item {[3]} Does the maximum likelihood estimator attain the Cramer-Rao lower bound for variance? 
    \end{enumerate}

    \item {[10]} The variables $X_1$, \ldots, $X_n$ are independent and gamma distributed with density
    \[
    f(x) = \begin{cases}
      \lambda^\alpha x^{\alpha - 1} \exp(-\lambda x) / \Gamma(\alpha), \text{ if } x\geq 0 \\
      0, \text{ otherwise}.
    \end{cases}  
    \]
    \begin{enumerate}
      \item {[5]} Find a sufficient statistic for $\alpha$ if we know that $\lambda = 1$. 
      \item {[5]} Find a two dimensional sufficient statistic for unknown $\alpha$ and $\lambda$. 
    \end{enumerate}

    \item We have two independent random samples $X_1$, $X_2$, \ldots, $X_{n_x}$ and $Y_1$, $Y_2$, \ldots, $Y_{n_y}$.
    The random variables $X_i$ follow Poisson distribution with intensity rate $\lambda_x$, 
    random variables $Y_i$ follow Poisson distribution with intensity rate $\lambda_y$.
  
    We would like to test $H_0$: $\lambda_x = \lambda_y$ against $H_1$: $\lambda_x \neq \lambda_y$.
  
    \begin{enumerate}
      \item {[3]} Find the maximal value of log-likelihood under $H_0$.
      \item {[3]} Find the maximal value of log-likelihood under unrestricted model.
      \item {[2]} Construct the likelihood ratio test. 
      \item {[2]} Do you reject $H_0$ if $n_x = 100$, $n_y = 200$, $\sum x_i = 500$, $\sum y_i = 900$ at
      significance level $5\%$?
    \end{enumerate}
  
    Hint: chi-squared critical values for $\alpha = 0.05$ are $\chi^2_{df=1} = 3.84$, $\chi^2_{df=2} = 5.99$.
  

\end{enumerate}




\subsection[2022-2023]{\hyperref[sec:sol_kr_04_2022_2023]{2022-2023}}
\label{sec:kr_04_2022_2023} % \label{ссылка сюда}

Short rules: 120 minutes, you may use one A4 cheat-sheet, offline +  online.

Notes: $W_t$ denotes the standard Wiener process, 
you may use standard normal cumulative distribution function in your answers.

Date: Balalayka day, 2023-06-23.

\begin{enumerate}

\item The weight of a fish $Y_i$ is a discrete random variables with 
distribution and observed frequencies given in the table 

\begin{tabular}{cccc}
    \toprule
    Weight [kg] & 1 & 2 & $a$ \\
    Probability & $0.2 + 0.1a$ & $0.3 - 0.1a$ & $0.5$ \\
    Observed frequency & $N_1$ & $N_2$ & $N_a$ \\
    \bottomrule
\end{tabular}

Fish weights $Y_i$ are independent, $a > 10$ is unknown. 

\begin{enumerate}
    \item Find the method of moments estimator of the parameter $a$. 
    \item Find the maximum likelihood estimator of the parameter $a$. 
\end{enumerate}


\item The $ETS(AAdN)$ model is given by the system
    \[
    \begin{cases}
    u_t  \sim \mathcal{N}(0;20) \\
    b_t = 0.9 b_{t-1} + 0.2 u_t \\
    \ell_t = \ell_{t-1} + 0.9 b_{t-1} + 0.3 u_t \\
    y_t = \ell_{t-1} + 0.9 b_{t-1} + u_t \\
    \end{cases}
    \]
    with $\ell_{100} = 20$ and $b_{100} = 2$.
\begin{enumerate}
    \item Find conditional probability $\P(y_{102} > 30 \mid \ell_{100}, b_{100})$.
    \item Approximately find the best point forecast for $y_{10000}$.
\end{enumerate}
    
\item Stochastic process $X_t$ is defined by $X_t = 7 + u_t + 0.3 u_{t-1}$, where $(u_t)$ is a white noise 
with variance $\sigma^2$.
\begin{enumerate}
    \item Is $(X_t)$ stationary? 
    \item Find the autocorrelation function of $(X_t)$.
    \item Find $\E(X_{t+2} \mid X_t, X_{t-1}, \ldots)$.
\end{enumerate}

\item Consider the process $X_t = \int_0^t W_u^2 dW_u + \int_0^t (W_u^2 + 2W_u u ) du - W_t^2 \cdot t$.

\begin{enumerate}
    \item Find $dX_t$ and the corresponding full form. 
    \item Is $X_t$ a martingale?
    \item Find $\E(X_t)$.
\end{enumerate}


\item Consider the Black and Scholes model with riskless rate $r$, volatility $\sigma$ and initial share price $S_0$. 

Find the current price $X_0$ of an option that pays you one dollar at time $T=2$ only if $S_2 > \exp(3r) S_0$.

\item A hedgehog moves at random on the vertices $A$, $B$, $C$ and $D$ of a regular tetrahedron (тетраэдр).
She start at the vertex $A$ and every minute changes her position to one of the adjacent vertices with probability $1/3$
independently of past moves. 

\begin{enumerate}
    \item Write down the transition matrix of this Markov chain. 
    \item What is the expected time of the first return to the starting vertex $A$?
\end{enumerate}

\end{enumerate}






\subsection[2021-2022]{\hyperref[sec:sol_kr_04_2021_2022]{2021-2022}}
\label{sec:kr_04_2021_2022} % \label{ссылка сюда}

Short rules: 120 minutes, offline, one A4 cheat sheet allowed.

Date: 2022-06-25

\begin{enumerate}

\item Consider $ETS(ANN)$ model,
	$
	\begin{cases}
	y_t = \ell_{t-1} + u_t \\
	\ell_t = \ell_{t-1} + \alpha u_t \\
	u_t \sim \cN(0;\sigma^2). \\
	\end{cases}
	$
Let $\ell_{99} = 50$, $\alpha = 1/2$, $\sigma^2 = 16$, $y_{98} = 48$, $y_{99} = 52$, $y_{100} = 55$. Calculate 95\% predictive interval for $y_{101}$.

\item Young investor Winnie-the-Crypto compares two trading strategies: buying bitcoins from good bees and from bad bees. 
Let $d_t$ be the price difference at day $t$ (bad minus good). 
Winnie-the-Crypto would like to test $H_0$: $\E(d_t) = 0$ against $H_a$: $\E(d_t) \neq 0$ at $5\%$ significance level.

Winnie assumed that $(d_t)$ can be approximated by a $MA(1)$ process and estimated the parameters using $T=400$ observations, $\hat d_t = 2 + u_t + 0.7 u_{t-1}$ 
with $\hat\sigma^2_u = 4$.

\begin{enumerate}
	\item Estimate $\E(d_t)$, $\Var(d_t)$ and $\Cov(d_t, d_{t-1})$.
	\item Estimate $\E(\bar d)$, $\Var(\bar d)$ and help Winnie by considering $Z = \frac{\bar d - 0}{se(\bar d)}$.
\end{enumerate}



\item The variables $X_1$, \ldots, $X_n$ are independent and uniformly distributed on $[0; 2a]$ for some positive $a$. 

\begin{enumerate}
	\item Find any sufficient statistic for $a$. 
	\item How the answer will change if $X_i \sim U[-a; 2a]$?
\end{enumerate}


\item Consider an estimator $\hat a$ with $\E(\hat a) = 0.5a + 3$. For the given sample size the Fisher information is $I_F(a) = 400/a^2$.
\begin{enumerate}
	\item What is the theoretical minimal variance of $\hat a$?
	\item Assume that $\hat a$ attains the minimal variance boundary and is asymptotically normal. Given that $\hat a = 2022$ provide 95\% CI for $a$.
\end{enumerate}

\item You observe $X_1$, \ldots, $X_{400}$ and $Y_1$, \ldots, $Y_{400}$, $\bar X = 5$, $\bar Y = 6$. 
All variables are independent. 

Consider the null hypothesis that all random variables are exponentially distributed with common parameter $\lambda$ against alternative
that parameter is $\lambda_X$ for every $X_i$ and $\lambda_Y$ for every $Y_j$. 

\begin{enumerate}
	\item Estimate common $\lambda$ using maximum likelihood for the restricted model. 
	\item Estimate both $\lambda_X$ and $\lambda_Y$ using maximum likelihood in the unrestricted model. 
	\item Use LR-test to test the null hyphotesis at 5\% significance level. 
\end{enumerate}

\item The ultimate goal of this exercise is to prove the good upper bound for tail probability of a normal distribution: 
if $X\sim \cN(0; \sigma^2)$ then $\P(X > c) \leq \exp(-c^2/2\sigma^2)$.

Here are the guiding hints (you free to use not use them): 

\begin{enumerate}
	\item State the MGF of $X$. You may derive it or simply write it if you remember.
	\item Consider $Y = \exp(uX)$. Using Markov inequality provide the upper bound for $\P(Y > \exp(uc))$.
	\item Prove that $\P(X > c) \leq MGF_X(u)\exp(-uc)$ for any $u$.
	\item Find the value of $u$ that makes the upper bound as tight as possible. 
\end{enumerate}


\item (bonus) Draw good bees and bad bees selling crypto. Any funny statistics/math joke is also ok!

\end{enumerate}





% \subsection[что идет в оглавление]{\hyperref[на что ссылка]{текст ссылки}}
\subsection[2020-2021]{\hyperref[sec:sol_kr_04_2020_2021]{2020-2021}}
\label{sec:kr_04_2020_2021} % \label{ссылка сюда}

Today: $+31^{\circ}$,  World Refrigiration Day :)

You have 100 minutes. You can use A4 cheat sheet and calculator. Be brave! 

Date: 2021-06-26

\begin{enumerate}

\item I throw a fair die until the sequence 626 appears. Let $N$ be the number of throws.
\begin{enumerate}
    \item What is the expected value $\E(N)$?
    \item Write down the system of linear equations for the moment generating function of $N$. You don't need to solve it!
\end{enumerate}
    

\item Consider the following stationary process
\[
y_t = 1 + 0.5 y_{t-2} + u_t + u_{t-1},    
\]
where random variables $u_t$ are independent $\cN(0; 4)$.

\begin{enumerate}
    \item Find the 95\% predictive interval for $y_{101}$ given that $y_{100} = 2$, $y_{99} = 3$, $y_{98} = 1$, $u_{99} = -1$.
    \item Find the point forecast for $y_{101}$ given that $y_{100}=2$.
\end{enumerate}


\item I have an unfair coin with probability of heads equal to $h \in (0;1)$.
\begin{enumerate}
    \item Let $N$ be the number of tails before the first head. Find the MGF of $N$.
    \item Let $S$ be the number of tails before $k$ heads (not necessary consecutive). Find the MGF of $S$.
    \item What is the limit of $MGF_S(t)$ when $k \to \infty$ and $k \times h \to 0.5$? What is the name of the corresponding distribution?
\end{enumerate}


\item Consider the stochastic process $X_t = f(t) \cos (2021 W_t)$.
\begin{enumerate}
    \item Find $dX_t$.
    \item Find any $f(t) \neq 0$ such that $X_t$ is a martingale.
    \item Using $f(t)$ from the previous point find $\E(\cos (2021 W_t))$.
\end{enumerate}




\end{enumerate}
