% !TEX root = ../tssp_exams.tex
% all problems are copied to stochastic_pro 2024-11-03


% it's good to follow the strategy:
% after exams copy exam here and classify int stochastic_pro

\newpage
\thispagestyle{empty}
\section{October exam}


\subsection[2025-2026]{\hyperref[sec:sol_kr_01_2025_2026]{2025-2026}}
\label{sec:kr_01_2025_2026} % \label{ссылка сюда}

\textcolor{red}{\textbf{FINAL SALE}}: Every problem will bring you 10 \sout{99.99} points!

Scratch paper price: \sout{10 points per sheet only} \textcolor{red}{\textbf{FREE\footnote[1]{Members only deal!}}}!

\begin{enumerate}
    \item Dragon Erik has three towns to kidnap a princess from: $A$, $B$ and $C$.
    He kidnaps the first princess from town $A$ and chooses every next town according to a Markov chain with transition matrix $T$,
    where states are written in alphabetical order:
    \[
    T = \begin{pmatrix}
        0.1 & 0.2 & ? \\
        ? &  0 & 0.7 \\
        0.2 & ? & 0.5 \\
    \end{pmatrix}.
    \]
    \begin{enumerate}
        \item {[2]} Fill in the missing values. 
        \item {[2]} Draw the graph of the Markov chain. 
        \item {[3]} What is the probability that the third princess will be from town $B$?
        \item {[3]} What is the probability that the second princess was from $A$ given that the third princess was from $B$?
    \end{enumerate}


    \item Every minute the cat Tikhon says «meow» with probability $1/3$ or «purr» with probability $2/3$ independently of all other words.
    For every «purr» that follows «meow» you get $1$ PEPE, for every «meow» that follows «purr» you pay $3$ PEPEs. 
    For «purr» that follows «purr» or «meow» that follows «meow» you get nothing. 

    You have just earned $1$ PEPE. 
    Let $T$ be the time to get the next positive reward. 
    \begin{enumerate}
        \item {[5]} Find $\E(T)$.
        \item {[5]} Find $\Var(T)$.
    \end{enumerate}

    \item {[10]} Gumbatali starts with zero initial sum $S_0 = 0$. 
    Every minute he either wins $X_t = 1$ dollar with probability $1/3$ or pays $1$ dollar, $X_t = -1$, with probability $2/3$.
    He can't go neither below $S_t = -2$ nor above $S_t = 3$, so that
    \[
    S_t = \min\{3, \max\{-2, S_{t-1} + X_t\}\}.
    \]
    The random variables $(X_t)$ are independent. 
    
    Find the stationary distribution of $S_t$.


\newpage
\item Consider the Markov chain:

\begin{tikzpicture}[
    node distance=50mm,
    state/.style={circle, draw=black, thick, minimum size=10mm, inner sep=1pt, font=\sffamily\large},
    every edge/.style={->, >=Stealth, semithick},
    lab/.style={fill=white, inner sep=1pt, font=\sffamily\small}
]

% --- nodes (arranged for a clear diagram) ---
\node[state] (2)  {2};
% absorbing
\node[state, above=20mm of 2] (1)  {1};

% closed class A member
\node[state, right=20mm of 2] (3) {3}; 
% closed class A member (loop)
\node[state, above=30mm of 3] (6) {5};  
 % closed class A member
\node[state, right=40mm of 2] (9) {4};           

% periodic closed class (small 2-cycle)
\node[state, right=100mm of 6] (4) {8};
\node[state, below=30mm of 4] (5) {10};

% transient / connector states on right
\node[state, right=70mm of 3] (7) {9};
\node[state, above=20mm of 7] (10) {7};
\node[state, left=25mm of 10] (11) {6};

% --- edges with probabilities ---
% state 1: absorbing
\draw[->] (1) to [loop above] node[lab] {1} ();

% state 2: transient -> 1 and -> 3
\draw[->] (2) to[bend right=20] node[lab, left] {0.9} (1);
\draw[->] (2) to[bend left=10] node[lab, above] {0.1} (3);

% closed class A: nodes 3,6,9 (aperiodic because 6 has self-loop)
\draw[->] (3) to[bend left=20] node[lab, left] {0.4} (6);
\draw[->] (3) to[bend left=10] node[lab, above] {0.6} (9);

\draw[->] (6) to[bend left=10] node[lab, above] {0.3} (3);
\draw[->] (6) to[bend right=10] node[lab, below] {} (9);
\draw[->] (6) to[loop above] node[lab] {0.3} ();

\draw[->] (9) to[bend left=10] node[lab, below] {0.6} (3);
\draw[->] (9) to[bend left=10] node[lab, right] {0.4} (6);

% periodic closed class (2-cycle): 4 <-> 5 (period 2)
\draw[->] (4) to[bend left=15] node[lab, above] {1} (5);
\draw[->] (5) to[bend left=15] node[lab, below] {1} (4);

% transient connectors on right
% to closed A
\draw[->] (7) to[bend left=10] node[lab, above] {0.5} (6);  
% to periodic closed class
\draw[->] (7) to[bend right=10] node[lab, below] {0.2} (4);  
% to transient 10
\draw[->] (7) to node[lab, above] {0.3} (10);               

% state 10: transient (flows to closed class 4 or to 11)
\draw[->] (10) to[bend left=12] node[lab, above] {0.3} (4);
\draw[->] (10) to[bend right=12] node[lab, above] {0.7} (11);

% state 11: transient (feeds back toward closed A or to 10)
\draw[->] (11) to[bend left=12] node[lab, above] {0.8} (6);
\draw[->] (11) to[bend right=12] node[lab, below] {0.2} (10);

\end{tikzpicture}

\begin{enumerate}
    \item {[5]} Using a chainsaw
    %\footnote[1]{We have excellent discounts on chainsaws today!} 
    cut the Markov chain into communicating classes and classify them as transient, positive recurrent or null-recurrent.
    \item {[1]} Is the chain irreducible?
    \item {[4]} Find the period of every state.
\end{enumerate}


    \item Let \( X \) be a Poisson distributed random variable with intensity \( \lambda = 2 \).  
The probability mass function of a Poisson random variable is:
\[
\P(X = k) = e^{-\lambda} \frac{ \lambda^k}{k!}, \quad k = 0, 1, 2, \dots
\]

\begin{enumerate}
    \item {[4]} Derive the moment generating function \( M_X(t) = \E(e^{tX})\).
    \item {[4]} Using moment generating function find the mean and variance of \(X\).
    \item {[2]} Let \( X_1 \sim \dPois(\lambda = 2) \) and \( X_2 \sim \dPois(\lambda = 3) \) be independent random variables. 
    Find the moment generating function of \( S = X_1 + X_2 \).
\end{enumerate}

\item By the mayor's decree, the city installs $T_n$ New Year's trees each day, \( n = 1, 2, \ldots \), starting from October 20th. 
The random variables $T_1, T_2, \dots$ are independent and take any natural value from $4$ to $10$ with equal probabilities. 

The amounts of snow $(W_n)$ are independent and uniformly distributed on $[0; 1/n]$. 

Determine the probability limits for the following sequences:
\begin{enumerate}
    \item {[2]} mayor's New Year kpi,   
    \(    X_n = \frac{1}{n} \sum_{i=1}^n T_i
    \)
    \item {[3]} the New Year's mood given by
    \(
    Y_n = \frac{2 X_n +1}{X_n + 3}
    \)
    \item {[5]} The average number of snowmen that can be built each day:
    \(
    S_n = \frac{1}{n} \sum_{i=1}^n W_i.
    \)
\end{enumerate}

\end{enumerate}


\subsection[2024-2025]{\hyperref[sec:sol_kr_01_2024_2025]{2024-2025}}
\label{sec:kr_01_2024_2025} % \label{ссылка сюда}


\begin{enumerate}
    \item {[10]} Michael stands in a corner of a hexagonal room with white soft walls. 
    Stochastic Processes course has caused him a deep trauma.
    Michael has insomnia and two independent personal identities.     
    At each iteration each personal identity moves from one vertex of the hexagon to the adjacent one.
    Two personal identities move independently with equal probabilities in both directions. 
    
    Consider the Markov chain where the state is a relative position of two identities of Michael in a hexagon. 
    \begin{enumerate}
        \item {[4]} Draw the diagram of chain states and find the transition matrix. 
        \item {[2]} Classify the states as transient or recurrent. 
        \item {[4]} Which proportion of his eternal life Michael spends in a perfect harmony with himself (two personal identities are located at the same vertex)?
    \end{enumerate}


    \item {[10]} Compare sigma-algebras and conditional expected values!
    
    \begin{enumerate}
        \item {[5]} Consider sigma-algebras 
        \[
        \cF_1 = \sigma(X), \quad \cF_2 = \sigma(Y), \quad \cF_3 = \sigma(X, Y), \quad \cF_4 = \sigma(X + Y, X - Y). %, \quad \cF_5 = \sigma(X, Y, X + Y).
        \]
        Which of them are always equal? Which sigma-algebra is always a subset of another one?

        \item {[5]} Consider random variables 
        \[
        R_1 = \E(X \mid Y), \quad R_2 = \E(1 / X \mid Y), \quad R_3 = \E(1 / X \mid 1/Y), \quad R_4 = \E(X \mid 1/Y). %, R_5 = 1 / \E(X \mid Y).
        \]
        Which of them are always equal provided that they exist?
    \end{enumerate}
    
    

    \item {[10]} The random variables $(X_n)$ are independent and uniform on $[0;1]$ and $S_n = X_1 + X_2 + \dots + X_n$.
    \begin{enumerate}
        \item {[4]} Find the moment generating function of $X_1$.
        \item {[2]} Find the moment generating function of $R = S_{10} - 5$.
        \item {[4]} Find $\E(X_1 \mid S_3)$.
        %\item {[4]} Find the moment generating function of $R_n = (S_n - n/2) / \sqrt{n/12}$.
    \end{enumerate}

    \newpage

    \item {[10]} I throw a fair coin. 
    Let $Y$ be the number of throws until I obtain the sequence head-tail-head. 

    \begin{enumerate}
        \item {[4]} Find $\E(Y)$.
        \item {[6]} Find $\E(Y^2)$ and hence $\Var(Y)$.
    \end{enumerate}


    \item {[10]} Consider two non-random sequences, $h_n = 1/n$ and $t_n = 1 + 1/n$.
    Elon Musk throws a fair coin once and selects the sequence $(h_n)$ if it lands on head and selects the sequence $(t_n)$ otherwise.
    Hence Elon obtains a random sequence $(X_n)$.

    \begin{enumerate}
        \item {[2]} What is the distribution of $X_5$?
        \item {[4]} What is the distribution of $\lim X_n$?
        \item {[4]} Write $\plim X_n$ explicitely as a function of $X_1$.
    \end{enumerate}
    
    \item {[10]} The random variables $(X_n)$ are independent and they have Poisson distribution with rate $\lambda = 2$. 
    Consider the cumulative sum $S_n = X_1 + X_2 + \dots + X_n$ with $S_0 = 0$
    and the natural filtration $\cF_n = \sigma(X_1, X_2, \dots, X_n)$.

    \begin{enumerate}
        \item {[4]} Provide two examples of events that belong to $\cF_9$ but do not belong to $\cF_7$.
        \item {[6]} Find all constants $a$ and $b$ such that $M_n = S_n + a + b \cdot n$ is a martingale. 
    \end{enumerate}

    Hint: if $R \sim \dPois(\lambda)$ then $\E(R) = \lambda$ and $\Var(R) = \lambda$. 

\end{enumerate}



\subsection[2023-2024]{\hyperref[sec:sol_kr_01_2023_2024]{2023-2024}}
\label{sec:kr_01_2023_2024} % \label{ссылка сюда}

Short rules: 90 minutes, offline. You may use one A4 cheat sheet.

Date: 2023-10-21.


\begin{enumerate} % all copied in stochastic_pro
  \item The hedgehog Melissa starts at the vertex $A$ of a triangle $\Delta ABC$.
  Each minute she randomly moves to an adjacent vertex with probabilities $\P(A \to B) = 0.7$, 
  $\P(A \to C) = 0.3$, $\P(B \to C) = \P(B \to A) = 0.5$,  $\P(C \to B) = \P(C \to A) = 0.5$.

  \begin{enumerate}
    \item What is the probability that she will be in vertex $B$ after 3 steps?
    \item Write down the transition matrix of this Markov chain. 
    \item What proportion of time Melissa will spend in each state in the long run?
  \end{enumerate}
  
  \item The number of players $N$ who will win the lottery
  is a random variable with probability mass function $\P(N = k) = 7\cdot 0.3^k / 3$ for $k\geq 1$.
  Each player will get a random prize $X_i \sim U[0;1]$.
  All random variables are independent. 
  Let $S$ be the sum of all the prizes. 

  \begin{enumerate}
    \item Find $\E(S \mid N)$ and conditional moment generating function $M_{S\mid N}(u)$.
    \item Find the unconditional moment generating function $M_S(u)$.
    \item What is the probabilistic meaning of $M_S''(0) - (M_S'(0))^2$? 
  \end{enumerate}

  Note: you don't need to calculate the value in (c). 
  
  \item Consider the stochastic process $(X_n)$, where $X_0$ is uniform on $[0;2]$ and
  $X_n = (1 + X_{n-1}) / 2$.

  \begin{enumerate}
    \item Find $\E(X_n)$ and $\Var(X_n)$.
    \item Find the probability limit $\plim X_n$.
  \end{enumerate}
  
  \item Students arrive in the Grusha café according to the Poisson arrival process $(X_t)$ 
  with constant rate $\lambda$. 

  The probability of no visitors during $5$ minutes is $0.05$. 
  
  \begin{enumerate}
    \item Find the value of $\lambda$.
    \item Find the variance and expected number of arrivals between $5$ pm and $8$ pm. 
    \item What is the probability of exactly $5$ arrivals between $5$ pm and $8$ pm?
  \end{enumerate}

  \item 
  The random variables $X_1$ and $X_2$ are independent and normally distributed, 
  $X_1 \sim \cN(1;1)$, $X_2 \sim \cN(2;2)$. 
  I choose $X_1$ with probability $0.3$ and $X_2$ with probability $0.7$ without knowing their values.
  
  Casino pays me the value $Y$ that is equal to the chosen random variable. 

  Let the indicator $I$ be equal to $1$ if I choose $X_1$ and $0$ otherwise. 

  \begin{enumerate}
    \item Express $Y$ in terms of $X_1$, $X_2$ and $I$.
    \item Find $\E(Y \mid I)$, $\Var(Y \mid I)$.
    \item Find $\E(Y)$ and $\Var(Y)$. 
  \end{enumerate}

  \item The joint distribution of $X$ and $Y$ is given in the table
    
    \begin{tabular}{*{4}{c}}
    \toprule
    & $X=-2$ & $X=0$ & $X=2$ \\
    \midrule
    $Y=-1$ & 0.1 & 0.2 & 0.3  \\
    $Y=1$ & 0.2 & 0.1 & 0.1  \\
    \bottomrule
    \end{tabular}
    
    \begin{enumerate}
     \item Explicitely find the $\sigma$-algebra $\sigma(X)$.
     \item How many elements are there in $\sigma(X \cdot Y)$?
    \end{enumerate}
    
\end{enumerate} % all copied in stochastic_pro


\subsection[2022-2023]{\hyperref[sec:sol_kr_01_2022_2023]{2022-2023}}
\label{sec:kr_01_2022_2023} % \label{ссылка сюда}

Short rules: 120 minutes, online and offline. You may use one A4 cheat sheet.

Date: 2022-10-29

\begin{enumerate}

  \item % in stochastic_pro 
  {[10]} The random variables $X_i$ are independend and uniformly distributed on $[0;2]$.
  Find 
      \[
      \plim_{n\to\infty}  \frac{(X_1 - \bar X)^3 + (X_2 - \bar X)^3 + \ldots + (X_n - \bar X)^3}{n + 2022}.
      \]
     
  
  \item A Hedgehog starts at the point $x=2$ on the real line. 
  Every minute he moves one step left with probability $0.3$ or one step right with probability $0.7$.
  There are two exceptions from this rule: the absorbing point $x=0$ and the reflecting barrier at $x=3$.
  
  If the Hedgehog reaches the absorbing point $x=0$ then he stops moving and stays there. 
  If the Hedgehog reaches the reflecting barrier $x=3$ then his next move will be one step left with probability $1$.
  
  \begin{enumerate}
  \item {[2]} Write the transition matrix of this Markov chain. 
  \item {[3]} What is the probability that Hedgehog will be at $x=1$ after exactly 3 steps?
  \item {[5]} What is the expected time to reach the absorbing state?
  \end{enumerate}
  
  
  \item The random variables $X_i$ are independent and they take values $+1$ or $-1$ with equal probability. 
  
  \begin{enumerate}
  \item {[3]} Explicitely list all the events in sigma-algebra $\sigma(X_1 \cdot X_2)$.
  \item {[3]} Pavel says that he knows only whether $X_1$ and $X_3$ are equal. 
  How will you describe his knowledge with sigma-algebra?
  \item {[4]} How many events are in the sigma-algebra $\sigma(X_1, X_1 + X_2, X_1 + X_2 + X_3)$?
  \end{enumerate}
  
  
  \item Masha receives on average 10 sms per minute. Sms arrival is well described by the Poisson process. 
  
  \begin{enumerate}
  \item {[3]} What is the probability that Masha receives exactly 10 sms in the next 40 seconds?
  \item {[3]} Masha just received an sms. What is the probability that she will wait more that 2.5 seconds before the next one?
  \item {[4]} Find the covariance between the number of sms in the first 3 minutes and the number of sms in the first 10 minutes. 
  \end{enumerate}
  
  
  \item The random variables $X_i$ are independent and they take values $+1$ or $-1$ with equal probability. 
  
  \begin{enumerate}
  \item {[3]} Find $\E(X_3 \mid X_1, X_2)$, $\E(X_3 \mid X_1 + X_3)$.
  \item {[3]} Find $\Var(X_3 \mid X_1, X_2, X_3)$, $\Var(X_3 \mid X_1 + X_3)$.
  \item {[4]} Let $Y_n$ be equal to $\E(X_1 + \ldots +  X_{2022} \mid X_1, X_2, \ldots, X_n)$. 
  
  Is the process $Y_1$, $Y_2$, \ldots, $Y_{2022}$ a martingale?
  \end{enumerate}
  
  
  \item Consider a Wiener process $(W_t)$.
  \begin{enumerate}
      \item {[4]} Let $Y_t = t W_{2t}$. What is the distribution of $Y_t - Y_s$ for $t\geq s$? Is $Y_t$ a Wiener process?
      \item {[6]} Find a constant $\alpha$ such that $M_t = W_t^3 + \alpha t W_t$ is a martingale. 
  \end{enumerate}
  
  
  
  \end{enumerate}
  



\subsection[2021-2022]{\hyperref[sec:sol_kr_01_2021_2022]{2021-2022}}
\label{sec:kr_01_2021_2022} % \label{ссылка сюда}

Short rules: 120 minutes, online without proctoring. You may use any source you want but don't cheat.

Date: 2021-10-28

\begin{enumerate}

\item (10 points) Consider the Markov chain with the transition matrix
\[
  P = \begin{pmatrix}
    0.2 & 0.2 & 0 & 0.6 \\
    0.3 & 0.3 & 0.4 & 0 \\
    0 & 0 & 0.1 & 0.9 \\
    0 & 0 & 0.8 & 0.2 \\
  \end{pmatrix}.
\]

\begin{enumerate}
  \item (3 points) Split the chain in classes and classify them into closed or not closed.
  \item (2 points) Classify the states into recurrent or transient.
  \item (5 points) A Hedgehog starts in the state one and moves 
  randomly between states according to the transition matrix.

  What is the approximate probability that the Hedgehog will be in the 
  state four after $10^{2021}$ moves?
\end{enumerate}

Note: state number is the row (or column) number.

  \item (10 points) Gleb Zheglov catches one criminal every day. 
  With probability $0.2$ the catched criminal is replaced by $w$ new criminals. 
  Initially there are $n$ criminals in the town. 

  What is the expected time to the ultimate crime eradication in the town?

  \begin{enumerate}
    \item (4 points) Solve the problem for $w=1$ and $n=1$.
    \item (6 points) Solve the problem for arbitrary $w$ and $n$.
  \end{enumerate}

  \item % in stochastic_pro
  (10 points) The random variables $X_i$ are independend and uniformly distributed on $[0;1]$.
  Find the probability limit
\[
\plim_{n\to\infty}  \max \left\{ \frac{\sum_{i=1}^n X_i}{n}, \frac{2\sum_{i=1}^n X^2_i}{n} \right\}.
\]



\item (10 points) Taxis arrive to the station according to the Poisson process with rate 1 per 5 minutes. 

Let $Y_t$ be the number of taxis that will arrive between 0 and $t$ minutes.

\begin{enumerate}
  \item (2 points) Sketch the expected value of $Y_t$ as a function of $t$.
  \item (8 points) Sketch the probability $\P(Y_t = Y_{60})$ as a function of $t$.
\end{enumerate}

Note: special points like intercepts or extrema should be explicitely marked.

\item (10 points) Prince Myshkin throws a fair coin until two consecutive heads appear. 
Let $N$ be the number of throws. 

Find the moment generating function of $N$. 

Hint: you may use the first step approach.

\item (20 points) Vincenzo Peruggia makes attempts to steal the Mona Lisa painting until the first 
success. 
Each attempt is successful with probability $0.1$.

Let $X$ be the number of attempts and $Z = \min\{X, 5\}$.

\begin{enumerate}
  \item (5 points) How many events are in sigma-algebras $\sigma(Z)$ and $\sigma(X)$?
  \item (5 points) If possible provide an example of events $A$ and $B$ such that: $A\in \sigma(Z)$ but $A\not\in\sigma(X)$; $B\in \sigma(X)$ but $B\not\in\sigma(Z)$.
  \item (10 points) Find $\E(Z \mid X)$ and $\E(X \mid Z)$.
\end{enumerate}






\end{enumerate}



% \subsection[что идет в оглавление]{\hyperref[на что ссылка]{текст ссылки}}
\subsection[2021-2022 retake]{\hyperref[sec:sol_kr_01_2021_2022_retake]{2021-2022 retake}}
\label{sec:kr_01_2021_2022_retake} % \label{ссылка сюда}


Short rules: 120 minutes, online without proctoring. You may use any source you want but don't cheat.

\begin{enumerate}

\item (10 points) Consider the Markov chain with the transition matrix
\[
  P = \begin{pmatrix}
    0.2 & 0.2 & 0 & 0.6 & 0 \\
    0.3 & 0.3 & 0.4 & 0 & 0\\
    0 & 0 & 0.3 & 0.7 & 0 \\
    0 & 0 & 0.8 & 0.2 & 0 \\
    0 & 0 & 0 & 0 & 1 \\
  \end{pmatrix}.
\]

\begin{enumerate}
  \item (3 points) Split the chain in classes and classify them into closed or not closed.
  \item (2 points) Classify the states into recurrent or transient.
  \item (5 points) A Hedgehog starts in the state one and moves 
  randomly between states according to the transition matrix.

  What is the approximate probability that the Hedgehog will be in the 
  state four after $10^{2021}$ moves?
\end{enumerate}

Note: state number is the row (or column) number.

  \item (10 points) Consider infinite ladder with steps numbered from $0$ to infinity. 
  I start at step $0$. Every day with probability $u$ I go one step up.
  With probability $d$ I go one step down. With probability $1-u-d$ I stay on the same step.

  If I am at step $0$ then I stay there with probability $1-u$ because it's impossible to go down. 

  Consider the case $d>u$. 
  
  What is the probability that I will be at step $0$ after $10^{1000}$ days?

  \item % in stochastic_pro  
  (10 points) The random variables $X_i$ are independend and uniformly distributed on $[0;2]$.
  Find the probability limit
\[
\plim_{n\to\infty}  \max \left\{ \frac{\sum_{i=1}^{10} X_i}{n}, \frac{\sum_{i=1}^n X^3_i}{n+1} \right\}.
\]


\item % in stochastic_pro 
(10 points) Taxis arrive to the station according to the Poisson process with rate 1 per 5 minutes. 

Let $Y_t$ be the number of taxis that will arrive between 0 and $t$ minutes.

\begin{enumerate}
  \item (5 points) Sketch the probability $\P(Y_{t+3} = 1 \mid Y_t = 0)$ as a function of $t$.
  \item (5 points) Sketch the covariance $\Cov(Y_t, Y_{60})$ as a function of $t$.
\end{enumerate}

Note: special points like intercepts or extrema should be explicitely marked.

\item (10 points) The moment generating function of a random variable $X$ is $1/(1-2t)$.
\begin{enumerate}
    \item Find the moment generating function of $2X$.
    \item Find the moment generating function of $X + Y$ where $X$ and $Y$ are independent and identically distributed.
    \item Do you remember the sum of geometric progression? Find $\E(X^{2021})$.
\end{enumerate}

\item (20 points) Variables $X_1$, $X_2$, \ldots $X_{100}$ are independent and identically distributed
with mean $1$ and variance $2$. Each $X_i$ has only three possible values: 0, 1, and 2. 

\begin{enumerate}
  \item (5 points) How many events are in sigma-algebras $\sigma(X_1, X_2)$ and $\sigma(X_1 - X_2)$?
  \item (5 points) If possible provide an example of events $A$ and $B$ such that: $A\in \sigma(X_1, X_2)$ but $A\not\in\sigma(X_1 - X_2)$; $B\in \sigma(X_1 - X_2)$ but $B\not\in\sigma(X_1, X_2)$.
  \item (10 points) Find $\E(X_1 + \ldots + X_{100} \mid X_1 + \ldots + X_{50})$ and $\E(X_1 + \ldots + X_{50} \mid X_1 + \ldots + X_{100})$.
\end{enumerate}






\end{enumerate}





% \subsection[что идет в оглавление]{\hyperref[на что ссылка]{текст ссылки}}
\subsection[2020-2021]{\hyperref[sec:sol_kr_01_2020_2021]{2020-2021}}
\label{sec:kr_01_2020_2021} % \label{ссылка сюда}



Here $(W_t)$ denotes the standard Wiener process.

Date: 2020-10-30

\begin{enumerate}
    
    
    
    \item For $r<s<t<u$ find the following expected values 
    \begin{enumerate}
    \item $\E((W_u - W_t)^2(W_s - W_r)^2)$;
    \item $\E((W_u - W_s)(W_t - W_r))$;
    \item $\E((W_t - W_r)(W_s - W_r)^2)$;
    \item $\E(W_r W_s W_t)$;
    \item $\E(W_r W_s W_t \mid W_s)$;
    \end{enumerate}

\item Consider Ito process $X_t$

\[
dX_t = \exp(t) W_t\, dt + \exp(2W_t) \, dW_t, \quad X_0 = 1.
\]

Consider two processes, $A_t = 1 + t^2 + X_t^3$ and $B_t = 1 + t^2 + X_t^3 W_t^4$.

\begin{enumerate}
    \item Find $dA_t$ and $dB_t$.
    \item Write the corresponding explicit expressions for $A_t$ and $B_t$:
    \[
    const + \int_0^t \ldots dW_u + \int_0^t \ldots du
    \]
    \item Check whether $X_t$ is a martingale.
\end{enumerate}

\item Let $S_0 = 0$, $S_t = X_1 + X_2 + \ldots + X_t$. The increments $X_t$ are independent and identically distributed: 

\begin{tabular}{cccc}
\toprule
$x$ & $-1$ & $0$ & $1$ \\
$\P(X_t = x)$ & $0.2$ & $0.2$ & $0.6$ \\
\bottomrule
\end{tabular}

\begin{enumerate}
    \item If possible find all constants $a$ such that $M_t = S_t + at$ is a martingale.
  \item If possible find all constants $b$ such that $R_t = b^{S_t}$ is a martingale.
\end{enumerate}

\item Consider the process $X_t$

\[
X_t= tW_t + \int_0^t uW_u^2\, dW_u.
\]

\begin{enumerate}
    \item Find $\E(X_t)$, $\Var(X_t)$.
    \item Find $dX_t$.
    \item Check whether $X_t$ is a martingale.
\end{enumerate}

\item A Hedgehog in the fog starts in $(0, 0)$ at $t=0$ and moves randomly with equal probabilities in four directions (north, south, east, west) by one unit every minute. 

Let $X_t$ and $Y_t$ be his coordinates after $t$ minutes and $S_t = X_t + Y_t$.

\begin{enumerate}
    \item Find $\E(X_2 \mid S_2)$;
    \item Find $\Var(X_2 \mid S_2)$.
\end{enumerate}

Hint: $\Var(Y \mid X) = \E(Y^2 \mid X) - (\E(Y \mid X))^2$.

    \item Vampire Petr and Markov Chains. 
    
    Vampire Petr drinks blood of a new victim every day. 
    Unfortunately 20\% of the population are vaccinated against vampires. 
    If more than one victim of the last three victims are vaccinated then Petr will be instantaneously cured and will return to the normal life. 
 
    For simplicity let's assume that the last three victims were not vaccinated. 
    
    \begin{enumerate}
        \item What is the probability that vampire Petr will be cured in the next three days?
        \item How many victims will be bitten by vampire Petr on average?
    \end{enumerate}
 
    \item Vampire Boris and Martingales.
    
    To survive vampire Boris needs to bite 70 talented students. 
    
    These 70 talented students have formed a secret group. They have written their emails on small pieces of paper and have randomly distributed these pieces among them. Each student has exactly one piece of paper with an email\footnote{The group is so secret that it is possible that a student has his own email on his piece of paper}. 
    
    Initially vampire Boris knows contacts of just two persons from the group. Today he will contact them, drink their blood and get the emails they have. Then vampire Boris will contact new victims and so on.
    
    \begin{enumerate}
        \item For $t\geq 1$ consider the process $M_t$, the proportion of non bitten students after the day $t$. 
        
        Is this process a martingale?
        
        \item Using martingale stopping theorem or otherwise find the probability that vampire Boris will bite all 70 students. 
    \end{enumerate}
 
 
\end{enumerate}


